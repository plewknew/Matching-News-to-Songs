{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Lyrics_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWQIJsD8Mb-r",
        "colab_type": "text"
      },
      "source": [
        "## Purpose\n",
        "\n",
        "The purpose of this notebook is to display a working example of how to use Google's universal sentence encoder to compare two different strings. The general idea is to apply some basic NLP techniques with Spacy in order to increase the weights of the 'important' aspects of a sentence, then apply the sentence encoder to get a vector representation of the sentances. These sentances are later compared.\n",
        "\n",
        "In general, there will be one news article that is inputted. This will be compared to a dataframe of songs that have already been processed by the encoder. The one with the best cosine similarity will be selected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-rVtjR-Mb-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from newspaper import Article\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.stem.snowball import EnglishStemmer\n",
        "import sentencepiece\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3-HoG0gMb-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def embed(text):\n",
        "    print('Start')\n",
        "    print('Starting embeddings...')\n",
        "    #embed_US = hub.Module(\"universal_sentence\")\n",
        "    embed_US = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder/2\")\n",
        "    embeddings = embed_US(text)\n",
        "    print('Extracting embeddings...')\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        sess.run(tf.tables_initializer())\n",
        "        embd = sess.run(embeddings)\n",
        "    dim_vector = ['Dim_{}'.format(i) for i in range(embd.shape[1])]\n",
        "    df_return = pd.DataFrame(embd, columns = dim_vector)\n",
        "    return df_return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjfcYRqeMb-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #First we want to import the particular article that we want\n",
        "article = Article('https://www.cbc.ca/news/world/cocaine-bust-philadelphia-ship-1.5180447')\n",
        "article.download()\n",
        "article.parse()\n",
        "article_text=article.text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrhriVN-Mb-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#now we import all of the song Lyrics (this should probably be done in another python script)\n",
        "df_songs = pd.DataFrame(pd.read_csv('lyrics.csv'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9T-v9LYMb-4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4090d370-3f69-4a98-9371-67d50386fbf6"
      },
      "source": [
        "political_artists = ['eminem-d12','eminem']#,'bob-marley' 'bob-marley-the-wailers','beyonce-knowles']\n",
        "df_songs_political = df_songs[df_songs['artist'].isin(political_artists)]\n",
        "df_songs_political.head()\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>song</th>\n",
              "      <th>year</th>\n",
              "      <th>artist</th>\n",
              "      <th>genre</th>\n",
              "      <th>lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>283031</th>\n",
              "      <td>283031</td>\n",
              "      <td>fight-music</td>\n",
              "      <td>2013</td>\n",
              "      <td>eminem-d12</td>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>[Chorus: Eminem]\\nThis kinda music\\nUse it and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>283032</th>\n",
              "      <td>283032</td>\n",
              "      <td>keep-talkin</td>\n",
              "      <td>2008</td>\n",
              "      <td>eminem-d12</td>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>Yeah, Detroit, motherfucka\\nDJ Green Lantern, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>283033</th>\n",
              "      <td>283033</td>\n",
              "      <td>i-ll-shit-on-you</td>\n",
              "      <td>2008</td>\n",
              "      <td>eminem-d12</td>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>I'll shit on you, da da, da da, da da\\nI'll sh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313003</th>\n",
              "      <td>313003</td>\n",
              "      <td>people-make-me</td>\n",
              "      <td>2009</td>\n",
              "      <td>eminem</td>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313004</th>\n",
              "      <td>313004</td>\n",
              "      <td>my-darling</td>\n",
              "      <td>2009</td>\n",
              "      <td>eminem</td>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>Ya look\\nIf I were to rap about the crap that'...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         index  ...                                             lyrics\n",
              "283031  283031  ...  [Chorus: Eminem]\\nThis kinda music\\nUse it and...\n",
              "283032  283032  ...  Yeah, Detroit, motherfucka\\nDJ Green Lantern, ...\n",
              "283033  283033  ...  I'll shit on you, da da, da da, da da\\nI'll sh...\n",
              "313003  313003  ...                                                NaN\n",
              "313004  313004  ...  Ya look\\nIf I were to rap about the crap that'...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JA5kQwniMb-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_songs_political=df_songs_political.dropna(subset=['lyrics'])\n",
        "df_songs_political['lyrics'] = df_songs_political['lyrics'].apply(lambda x: x.replace('\\n',' '))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pILJLzrMb_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_songs_politcal_lyrics= list(df_songs_political.iloc[:,5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeDmLCdoMb_E",
        "colab_type": "text"
      },
      "source": [
        "## Here we begin to implement some of the NLP\n",
        "\n",
        "Implement stemming after"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5niVr4fMb_F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This cell removes stop words and weights the description to focus on Nouns, Adjectives, and Verbs.\n",
        "def nlp_weighting(input_list):\n",
        "    print('Start')\n",
        "    nlp = spacy.load('en')\n",
        "    newtext = []\n",
        "\n",
        "    for doc in input_list:\n",
        "        nlpdoc=nlp(doc)\n",
        "        tempDoc=''\n",
        "        for token in nlpdoc:\n",
        "            if token.is_stop == False:\n",
        "                tempDoc = tempDoc + ' ' + str(token.lemma_)\n",
        "                if token.pos_ == 'NOUN':\n",
        "                    #We triple the strength of Nouns\n",
        "                    tempDoc = tempDoc + ' ' + str(token.lemma_)\n",
        "                    tempDoc = tempDoc + ' ' + str(token.lemma_)\n",
        "                elif  token.pos_ == 'ADJ':\n",
        "                    #We double the strength fo Adjectives\n",
        "                    tempDoc = tempDoc + ' ' + str(token.lemma_)\n",
        "                elif token.pos_ == 'VERB':\n",
        "                    #We double the strength of Verbs\n",
        "                    tempDoc = tempDoc + ' ' + str(token.lemma_)\n",
        "                    \n",
        "        #Here we have a hard cutoff at 2100 characters. THis is because there were memory issues with the encoding otherwise\n",
        "        if len(tempDoc) > 2100:\n",
        "            tempDoc = tempDoc[0:2100]\n",
        "        if len(tempDoc) < 110:\n",
        "            tempDoc =''\n",
        "\n",
        "        newtext.append(tempDoc)\n",
        "        \n",
        "    print('Returned')\n",
        "        \n",
        "    return(newtext)\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w0NvpK6Mb_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8e3bcead-4e7a-4fbf-ff16-1528687a81b1"
      },
      "source": [
        "df_songs_politcal_lyrics = nlp_weighting(df_songs_politcal_lyrics)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start\n",
            "Returned\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTp2O36fMb_K",
        "colab_type": "text"
      },
      "source": [
        "Note below we have the version where we are taking TFIDF Weights. In reality, this would be harder to implement. In practice, we will use a pretrained model that will be able to return a vector to compare similarities. Also, we will want to restrict the size of our data in order to make comparisons feasible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-Ojc5nCMb_P",
        "colab_type": "text"
      },
      "source": [
        "Implement embedding below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGk3kuskMb_Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a8d850a9-532e-43f9-c8eb-6cc934a5303a"
      },
      "source": [
        "len(df_songs_politcal_lyrics)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "581"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKBI4hR0Mb_T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "2856db79-7f7f-4aa3-e866-8762de974b74"
      },
      "source": [
        "df_songs_political_lyrics_embed = embed(df_songs_politcal_lyrics)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start\n",
            "Starting embeddings...\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting embeddings...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KkPjd62Mb_V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "f6d84c80-3994-41b9-87b8-85591737ca94"
      },
      "source": [
        "df_songs_political_lyrics_embed.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dim_0</th>\n",
              "      <th>Dim_1</th>\n",
              "      <th>Dim_2</th>\n",
              "      <th>Dim_3</th>\n",
              "      <th>Dim_4</th>\n",
              "      <th>Dim_5</th>\n",
              "      <th>Dim_6</th>\n",
              "      <th>Dim_7</th>\n",
              "      <th>Dim_8</th>\n",
              "      <th>Dim_9</th>\n",
              "      <th>Dim_10</th>\n",
              "      <th>Dim_11</th>\n",
              "      <th>Dim_12</th>\n",
              "      <th>Dim_13</th>\n",
              "      <th>Dim_14</th>\n",
              "      <th>Dim_15</th>\n",
              "      <th>Dim_16</th>\n",
              "      <th>Dim_17</th>\n",
              "      <th>Dim_18</th>\n",
              "      <th>Dim_19</th>\n",
              "      <th>Dim_20</th>\n",
              "      <th>Dim_21</th>\n",
              "      <th>Dim_22</th>\n",
              "      <th>Dim_23</th>\n",
              "      <th>Dim_24</th>\n",
              "      <th>Dim_25</th>\n",
              "      <th>Dim_26</th>\n",
              "      <th>Dim_27</th>\n",
              "      <th>Dim_28</th>\n",
              "      <th>Dim_29</th>\n",
              "      <th>Dim_30</th>\n",
              "      <th>Dim_31</th>\n",
              "      <th>Dim_32</th>\n",
              "      <th>Dim_33</th>\n",
              "      <th>Dim_34</th>\n",
              "      <th>Dim_35</th>\n",
              "      <th>Dim_36</th>\n",
              "      <th>Dim_37</th>\n",
              "      <th>Dim_38</th>\n",
              "      <th>Dim_39</th>\n",
              "      <th>...</th>\n",
              "      <th>Dim_472</th>\n",
              "      <th>Dim_473</th>\n",
              "      <th>Dim_474</th>\n",
              "      <th>Dim_475</th>\n",
              "      <th>Dim_476</th>\n",
              "      <th>Dim_477</th>\n",
              "      <th>Dim_478</th>\n",
              "      <th>Dim_479</th>\n",
              "      <th>Dim_480</th>\n",
              "      <th>Dim_481</th>\n",
              "      <th>Dim_482</th>\n",
              "      <th>Dim_483</th>\n",
              "      <th>Dim_484</th>\n",
              "      <th>Dim_485</th>\n",
              "      <th>Dim_486</th>\n",
              "      <th>Dim_487</th>\n",
              "      <th>Dim_488</th>\n",
              "      <th>Dim_489</th>\n",
              "      <th>Dim_490</th>\n",
              "      <th>Dim_491</th>\n",
              "      <th>Dim_492</th>\n",
              "      <th>Dim_493</th>\n",
              "      <th>Dim_494</th>\n",
              "      <th>Dim_495</th>\n",
              "      <th>Dim_496</th>\n",
              "      <th>Dim_497</th>\n",
              "      <th>Dim_498</th>\n",
              "      <th>Dim_499</th>\n",
              "      <th>Dim_500</th>\n",
              "      <th>Dim_501</th>\n",
              "      <th>Dim_502</th>\n",
              "      <th>Dim_503</th>\n",
              "      <th>Dim_504</th>\n",
              "      <th>Dim_505</th>\n",
              "      <th>Dim_506</th>\n",
              "      <th>Dim_507</th>\n",
              "      <th>Dim_508</th>\n",
              "      <th>Dim_509</th>\n",
              "      <th>Dim_510</th>\n",
              "      <th>Dim_511</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.043546</td>\n",
              "      <td>-0.046377</td>\n",
              "      <td>-0.014012</td>\n",
              "      <td>-0.033482</td>\n",
              "      <td>-0.055708</td>\n",
              "      <td>-0.016451</td>\n",
              "      <td>-0.028052</td>\n",
              "      <td>-0.029006</td>\n",
              "      <td>-0.002859</td>\n",
              "      <td>-0.051293</td>\n",
              "      <td>0.053667</td>\n",
              "      <td>0.023362</td>\n",
              "      <td>-0.051412</td>\n",
              "      <td>0.055936</td>\n",
              "      <td>0.038279</td>\n",
              "      <td>0.051678</td>\n",
              "      <td>-0.044512</td>\n",
              "      <td>-0.012593</td>\n",
              "      <td>0.051773</td>\n",
              "      <td>0.012877</td>\n",
              "      <td>-0.052250</td>\n",
              "      <td>-0.047550</td>\n",
              "      <td>0.046867</td>\n",
              "      <td>0.041088</td>\n",
              "      <td>0.047814</td>\n",
              "      <td>0.003871</td>\n",
              "      <td>-0.038804</td>\n",
              "      <td>0.033263</td>\n",
              "      <td>0.046392</td>\n",
              "      <td>0.035826</td>\n",
              "      <td>-0.031177</td>\n",
              "      <td>0.054402</td>\n",
              "      <td>0.052534</td>\n",
              "      <td>-0.039143</td>\n",
              "      <td>0.014950</td>\n",
              "      <td>0.049223</td>\n",
              "      <td>-0.053642</td>\n",
              "      <td>-0.018879</td>\n",
              "      <td>0.039539</td>\n",
              "      <td>0.033272</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.055726</td>\n",
              "      <td>0.055944</td>\n",
              "      <td>-0.054300</td>\n",
              "      <td>0.053138</td>\n",
              "      <td>-0.052542</td>\n",
              "      <td>0.055765</td>\n",
              "      <td>-0.055936</td>\n",
              "      <td>0.012610</td>\n",
              "      <td>0.048227</td>\n",
              "      <td>-0.039743</td>\n",
              "      <td>0.014616</td>\n",
              "      <td>-0.003097</td>\n",
              "      <td>-0.048924</td>\n",
              "      <td>-0.030053</td>\n",
              "      <td>-0.055942</td>\n",
              "      <td>0.053398</td>\n",
              "      <td>-0.054866</td>\n",
              "      <td>0.004922</td>\n",
              "      <td>-0.048198</td>\n",
              "      <td>0.044411</td>\n",
              "      <td>0.023653</td>\n",
              "      <td>0.055739</td>\n",
              "      <td>0.054967</td>\n",
              "      <td>-0.053261</td>\n",
              "      <td>0.055898</td>\n",
              "      <td>-0.013618</td>\n",
              "      <td>0.051285</td>\n",
              "      <td>0.042338</td>\n",
              "      <td>0.037476</td>\n",
              "      <td>0.026317</td>\n",
              "      <td>-0.049983</td>\n",
              "      <td>-0.003013</td>\n",
              "      <td>0.055946</td>\n",
              "      <td>-0.055643</td>\n",
              "      <td>0.053186</td>\n",
              "      <td>-0.055921</td>\n",
              "      <td>0.049664</td>\n",
              "      <td>-0.022258</td>\n",
              "      <td>-0.055845</td>\n",
              "      <td>0.055201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.003506</td>\n",
              "      <td>0.043842</td>\n",
              "      <td>0.021781</td>\n",
              "      <td>-0.046783</td>\n",
              "      <td>-0.051274</td>\n",
              "      <td>0.025513</td>\n",
              "      <td>-0.050620</td>\n",
              "      <td>-0.036133</td>\n",
              "      <td>-0.050709</td>\n",
              "      <td>-0.045455</td>\n",
              "      <td>0.051265</td>\n",
              "      <td>-0.016655</td>\n",
              "      <td>-0.016872</td>\n",
              "      <td>0.051274</td>\n",
              "      <td>0.049925</td>\n",
              "      <td>0.051271</td>\n",
              "      <td>-0.043107</td>\n",
              "      <td>-0.051254</td>\n",
              "      <td>-0.018499</td>\n",
              "      <td>0.049012</td>\n",
              "      <td>-0.051197</td>\n",
              "      <td>-0.051272</td>\n",
              "      <td>0.011642</td>\n",
              "      <td>-0.013668</td>\n",
              "      <td>0.051172</td>\n",
              "      <td>0.028110</td>\n",
              "      <td>-0.011781</td>\n",
              "      <td>0.010968</td>\n",
              "      <td>-0.050718</td>\n",
              "      <td>0.050289</td>\n",
              "      <td>0.001409</td>\n",
              "      <td>0.001439</td>\n",
              "      <td>-0.015662</td>\n",
              "      <td>-0.000218</td>\n",
              "      <td>-0.011160</td>\n",
              "      <td>0.051249</td>\n",
              "      <td>-0.051252</td>\n",
              "      <td>-0.000600</td>\n",
              "      <td>-0.022180</td>\n",
              "      <td>-0.015449</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.050532</td>\n",
              "      <td>0.051274</td>\n",
              "      <td>-0.051005</td>\n",
              "      <td>0.042976</td>\n",
              "      <td>-0.051159</td>\n",
              "      <td>0.051255</td>\n",
              "      <td>-0.051258</td>\n",
              "      <td>0.001217</td>\n",
              "      <td>0.051201</td>\n",
              "      <td>-0.050498</td>\n",
              "      <td>0.023989</td>\n",
              "      <td>-0.047935</td>\n",
              "      <td>0.045304</td>\n",
              "      <td>-0.031570</td>\n",
              "      <td>-0.051272</td>\n",
              "      <td>0.051206</td>\n",
              "      <td>-0.051272</td>\n",
              "      <td>0.050735</td>\n",
              "      <td>-0.019595</td>\n",
              "      <td>0.043849</td>\n",
              "      <td>-0.005618</td>\n",
              "      <td>0.051185</td>\n",
              "      <td>0.051273</td>\n",
              "      <td>-0.005908</td>\n",
              "      <td>0.051274</td>\n",
              "      <td>-0.050580</td>\n",
              "      <td>0.043078</td>\n",
              "      <td>0.049279</td>\n",
              "      <td>0.035611</td>\n",
              "      <td>-0.040589</td>\n",
              "      <td>-0.050921</td>\n",
              "      <td>0.013184</td>\n",
              "      <td>0.051274</td>\n",
              "      <td>-0.051274</td>\n",
              "      <td>0.050398</td>\n",
              "      <td>-0.051274</td>\n",
              "      <td>0.047869</td>\n",
              "      <td>0.050948</td>\n",
              "      <td>-0.051272</td>\n",
              "      <td>0.051257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.002697</td>\n",
              "      <td>-0.051373</td>\n",
              "      <td>0.022568</td>\n",
              "      <td>-0.050184</td>\n",
              "      <td>-0.053002</td>\n",
              "      <td>-0.049322</td>\n",
              "      <td>-0.049312</td>\n",
              "      <td>-0.027400</td>\n",
              "      <td>-0.042388</td>\n",
              "      <td>-0.052793</td>\n",
              "      <td>0.052982</td>\n",
              "      <td>0.043161</td>\n",
              "      <td>-0.052176</td>\n",
              "      <td>0.041648</td>\n",
              "      <td>0.049289</td>\n",
              "      <td>0.053044</td>\n",
              "      <td>0.002314</td>\n",
              "      <td>-0.037124</td>\n",
              "      <td>0.044187</td>\n",
              "      <td>0.006503</td>\n",
              "      <td>-0.051850</td>\n",
              "      <td>-0.034948</td>\n",
              "      <td>0.044539</td>\n",
              "      <td>0.006391</td>\n",
              "      <td>0.050408</td>\n",
              "      <td>-0.007173</td>\n",
              "      <td>-0.051856</td>\n",
              "      <td>-0.038889</td>\n",
              "      <td>-0.049801</td>\n",
              "      <td>0.025422</td>\n",
              "      <td>0.001417</td>\n",
              "      <td>0.000536</td>\n",
              "      <td>0.017925</td>\n",
              "      <td>0.050527</td>\n",
              "      <td>0.002679</td>\n",
              "      <td>0.053064</td>\n",
              "      <td>-0.051955</td>\n",
              "      <td>0.000199</td>\n",
              "      <td>0.051017</td>\n",
              "      <td>0.047810</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.048877</td>\n",
              "      <td>0.053073</td>\n",
              "      <td>-0.052839</td>\n",
              "      <td>0.039596</td>\n",
              "      <td>-0.052893</td>\n",
              "      <td>0.050257</td>\n",
              "      <td>-0.053079</td>\n",
              "      <td>0.040647</td>\n",
              "      <td>0.023479</td>\n",
              "      <td>-0.046963</td>\n",
              "      <td>-0.047918</td>\n",
              "      <td>-0.051605</td>\n",
              "      <td>0.024196</td>\n",
              "      <td>0.010640</td>\n",
              "      <td>-0.053081</td>\n",
              "      <td>0.048377</td>\n",
              "      <td>-0.053000</td>\n",
              "      <td>-0.025640</td>\n",
              "      <td>-0.023859</td>\n",
              "      <td>0.031428</td>\n",
              "      <td>0.025570</td>\n",
              "      <td>0.053069</td>\n",
              "      <td>0.052906</td>\n",
              "      <td>0.041750</td>\n",
              "      <td>0.053041</td>\n",
              "      <td>0.024757</td>\n",
              "      <td>0.051872</td>\n",
              "      <td>0.048532</td>\n",
              "      <td>0.001577</td>\n",
              "      <td>-0.018895</td>\n",
              "      <td>-0.053058</td>\n",
              "      <td>0.031322</td>\n",
              "      <td>0.053080</td>\n",
              "      <td>-0.053073</td>\n",
              "      <td>0.051952</td>\n",
              "      <td>-0.053045</td>\n",
              "      <td>0.052621</td>\n",
              "      <td>0.052023</td>\n",
              "      <td>-0.052959</td>\n",
              "      <td>0.052749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.044234</td>\n",
              "      <td>0.016732</td>\n",
              "      <td>0.039142</td>\n",
              "      <td>0.014995</td>\n",
              "      <td>-0.051512</td>\n",
              "      <td>-0.010867</td>\n",
              "      <td>-0.046778</td>\n",
              "      <td>-0.048023</td>\n",
              "      <td>-0.049232</td>\n",
              "      <td>-0.049120</td>\n",
              "      <td>0.051501</td>\n",
              "      <td>0.040127</td>\n",
              "      <td>0.031349</td>\n",
              "      <td>0.051513</td>\n",
              "      <td>0.049891</td>\n",
              "      <td>0.051491</td>\n",
              "      <td>-0.049659</td>\n",
              "      <td>-0.051510</td>\n",
              "      <td>-0.004021</td>\n",
              "      <td>0.051088</td>\n",
              "      <td>-0.048757</td>\n",
              "      <td>-0.051510</td>\n",
              "      <td>-0.046646</td>\n",
              "      <td>-0.050969</td>\n",
              "      <td>-0.031060</td>\n",
              "      <td>0.045033</td>\n",
              "      <td>-0.032078</td>\n",
              "      <td>0.043303</td>\n",
              "      <td>-0.049398</td>\n",
              "      <td>0.048492</td>\n",
              "      <td>0.033718</td>\n",
              "      <td>0.044021</td>\n",
              "      <td>0.030418</td>\n",
              "      <td>-0.033932</td>\n",
              "      <td>0.049070</td>\n",
              "      <td>-0.007646</td>\n",
              "      <td>-0.043801</td>\n",
              "      <td>-0.049927</td>\n",
              "      <td>0.050049</td>\n",
              "      <td>-0.039664</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.049972</td>\n",
              "      <td>0.051513</td>\n",
              "      <td>-0.048868</td>\n",
              "      <td>0.049629</td>\n",
              "      <td>-0.051484</td>\n",
              "      <td>0.051481</td>\n",
              "      <td>-0.051513</td>\n",
              "      <td>-0.051437</td>\n",
              "      <td>0.045637</td>\n",
              "      <td>0.025813</td>\n",
              "      <td>0.017431</td>\n",
              "      <td>0.049011</td>\n",
              "      <td>0.043400</td>\n",
              "      <td>-0.048180</td>\n",
              "      <td>-0.051503</td>\n",
              "      <td>0.050818</td>\n",
              "      <td>-0.051513</td>\n",
              "      <td>0.036421</td>\n",
              "      <td>-0.006904</td>\n",
              "      <td>0.051502</td>\n",
              "      <td>-0.000419</td>\n",
              "      <td>0.050034</td>\n",
              "      <td>0.051491</td>\n",
              "      <td>-0.051422</td>\n",
              "      <td>0.051513</td>\n",
              "      <td>-0.051227</td>\n",
              "      <td>-0.015385</td>\n",
              "      <td>0.008416</td>\n",
              "      <td>0.047469</td>\n",
              "      <td>-0.048844</td>\n",
              "      <td>-0.049808</td>\n",
              "      <td>0.048959</td>\n",
              "      <td>0.051513</td>\n",
              "      <td>-0.051513</td>\n",
              "      <td>0.045779</td>\n",
              "      <td>-0.051513</td>\n",
              "      <td>0.034426</td>\n",
              "      <td>-0.004095</td>\n",
              "      <td>-0.051497</td>\n",
              "      <td>0.050780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.020392</td>\n",
              "      <td>0.052606</td>\n",
              "      <td>0.012197</td>\n",
              "      <td>-0.040473</td>\n",
              "      <td>-0.054818</td>\n",
              "      <td>-0.006115</td>\n",
              "      <td>-0.034589</td>\n",
              "      <td>-0.028364</td>\n",
              "      <td>-0.050616</td>\n",
              "      <td>-0.038945</td>\n",
              "      <td>0.054817</td>\n",
              "      <td>0.038759</td>\n",
              "      <td>-0.053308</td>\n",
              "      <td>0.054816</td>\n",
              "      <td>0.053928</td>\n",
              "      <td>0.053771</td>\n",
              "      <td>-0.053332</td>\n",
              "      <td>-0.052260</td>\n",
              "      <td>0.028108</td>\n",
              "      <td>0.050143</td>\n",
              "      <td>-0.052209</td>\n",
              "      <td>-0.054399</td>\n",
              "      <td>0.018219</td>\n",
              "      <td>-0.033890</td>\n",
              "      <td>0.035585</td>\n",
              "      <td>0.025232</td>\n",
              "      <td>-0.032538</td>\n",
              "      <td>0.017320</td>\n",
              "      <td>-0.050271</td>\n",
              "      <td>-0.020892</td>\n",
              "      <td>0.024738</td>\n",
              "      <td>0.022261</td>\n",
              "      <td>0.029353</td>\n",
              "      <td>-0.010272</td>\n",
              "      <td>0.040482</td>\n",
              "      <td>0.052811</td>\n",
              "      <td>-0.054786</td>\n",
              "      <td>-0.049223</td>\n",
              "      <td>0.050518</td>\n",
              "      <td>0.044019</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.053965</td>\n",
              "      <td>0.054817</td>\n",
              "      <td>-0.051637</td>\n",
              "      <td>-0.037153</td>\n",
              "      <td>-0.039287</td>\n",
              "      <td>0.054117</td>\n",
              "      <td>-0.054802</td>\n",
              "      <td>-0.034117</td>\n",
              "      <td>0.052569</td>\n",
              "      <td>-0.047343</td>\n",
              "      <td>0.016884</td>\n",
              "      <td>-0.054682</td>\n",
              "      <td>-0.015364</td>\n",
              "      <td>-0.052025</td>\n",
              "      <td>-0.049880</td>\n",
              "      <td>0.052987</td>\n",
              "      <td>-0.054611</td>\n",
              "      <td>-0.014542</td>\n",
              "      <td>-0.047643</td>\n",
              "      <td>0.053957</td>\n",
              "      <td>-0.031519</td>\n",
              "      <td>0.054805</td>\n",
              "      <td>0.054499</td>\n",
              "      <td>0.030767</td>\n",
              "      <td>0.054817</td>\n",
              "      <td>-0.052341</td>\n",
              "      <td>0.053161</td>\n",
              "      <td>0.052553</td>\n",
              "      <td>0.035241</td>\n",
              "      <td>-0.045290</td>\n",
              "      <td>-0.054740</td>\n",
              "      <td>-0.006768</td>\n",
              "      <td>0.054818</td>\n",
              "      <td>-0.054772</td>\n",
              "      <td>0.052424</td>\n",
              "      <td>-0.054817</td>\n",
              "      <td>0.046180</td>\n",
              "      <td>0.053930</td>\n",
              "      <td>-0.054788</td>\n",
              "      <td>0.048527</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 512 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Dim_0     Dim_1     Dim_2  ...   Dim_509   Dim_510   Dim_511\n",
              "0 -0.043546 -0.046377 -0.014012  ... -0.022258 -0.055845  0.055201\n",
              "1 -0.003506  0.043842  0.021781  ...  0.050948 -0.051272  0.051257\n",
              "2  0.002697 -0.051373  0.022568  ...  0.052023 -0.052959  0.052749\n",
              "3 -0.044234  0.016732  0.039142  ... -0.004095 -0.051497  0.050780\n",
              "4 -0.020392  0.052606  0.012197  ...  0.053930 -0.054788  0.048527\n",
              "\n",
              "[5 rows x 512 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuHdQFH6Mb_Y",
        "colab_type": "text"
      },
      "source": [
        "### Below we apply the NLP to the Article\n",
        "\n",
        "We will use the functions from above to do this"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVHbnN63Mb_Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "450ed0d1-e4b2-411d-b6f5-e119c22d0152"
      },
      "source": [
        "article_text = nlp_weighting([article_text])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start\n",
            "Returned\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpyd4FETMb_h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "96bc4147-a259-4a97-cf88-3f8769d04d3d"
      },
      "source": [
        "article_text_embed = embed([article_text[0],'temp']).iloc[0,:]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start\n",
            "Starting embeddings...\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting embeddings...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxkDnIRTMb_o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "bf8b190a-5f69-4fbc-e38e-6af4294a3c5d"
      },
      "source": [
        "max_cos = 0\n",
        "max_col = ''\n",
        "for i in range(len(df_songs_political_lyrics_embed)):\n",
        "    temp_cos = cosine_similarity([article_text_embed],[df_songs_political_lyrics_embed.iloc[i]])\n",
        "    if temp_cos > max_cos:\n",
        "        max_cos = temp_cos\n",
        "        max_col = df_songs_political.iloc[i]\n",
        "print(max_col)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "index                                                313122\n",
            "song                                             by-my-side\n",
            "year                                                   2007\n",
            "artist                                               eminem\n",
            "genre                                               Hip-Hop\n",
            "lyrics    OH! Stat Quo Here we go Come on, come on You r...\n",
            "Name: 313122, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S6cuXQ4ed0X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}