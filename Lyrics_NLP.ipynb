{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "The purpose of this notebook is to display a working example of how to use Google's universal sentence encoder to compare two different strings. The general idea is to apply some basic NLP techniques with Spacy in order to increase the weights of the 'important' aspects of a sentence, then apply the sentence encoder to get a vector representation of the sentances. These sentances are later compared.\n",
    "\n",
    "In general, there will be one news article that is inputted. This will be compared to a dataframe of songs that have already been processed by the encoder. The one with the best cosine similarity will be selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from newspaper import Article\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "import sentencepiece\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(text):\n",
    "    print('Start')\n",
    "    text_list = list(text)\n",
    "    embed = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder/2\")\n",
    "    embeddings = embed(text_list)\n",
    "    print('Extracting embeddings...')\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.tables_initializer())\n",
    "        embd = sess.run(embeddings)\n",
    "    dim_vector = ['Dim_{}'.format(i) for i in range(embd.shape[1])]\n",
    "    df_return = pd.DataFrame(embd, columns = dim_vector)\n",
    "    return df_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we want to import the particular article that we want\n",
    "article = Article('https://www.cbc.ca/news/world/cocaine-bust-philadelphia-ship-1.5180447')\n",
    "article.download()\n",
    "article.parse()\n",
    "article_text=article.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we import all of the song Lyrics (this should probably be done in another python script)\n",
    "df_songs = pd.DataFrame(pd.read_csv('lyrics.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# unique = df_songs['artist'].unique()\n",
    "# for i in range(len(unique)):\n",
    "#     print(unique[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>song</th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ego-remix</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Oh baby, how you doing?\\nYou know I'm gonna cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>then-tell-me</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>playin' everything so easy,\\nit's like you see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>honesty</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>If you search\\nFor tenderness\\nIt isn't hard t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>you-are-my-rock</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Oh oh oh I, oh oh oh I\\n[Verse 1:]\\nIf I wrote...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>black-culture</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Party the people, the people the party it's po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index             song  year           artist genre  \\\n",
       "0      0        ego-remix  2009  beyonce-knowles   Pop   \n",
       "1      1     then-tell-me  2009  beyonce-knowles   Pop   \n",
       "2      2          honesty  2009  beyonce-knowles   Pop   \n",
       "3      3  you-are-my-rock  2009  beyonce-knowles   Pop   \n",
       "4      4    black-culture  2009  beyonce-knowles   Pop   \n",
       "\n",
       "                                              lyrics  \n",
       "0  Oh baby, how you doing?\\nYou know I'm gonna cu...  \n",
       "1  playin' everything so easy,\\nit's like you see...  \n",
       "2  If you search\\nFor tenderness\\nIt isn't hard t...  \n",
       "3  Oh oh oh I, oh oh oh I\\n[Verse 1:]\\nIf I wrote...  \n",
       "4  Party the people, the people the party it's po...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "political_artists = ['bob-marley', 'bob-marley-the-wailers','eminem-d12','eminem','beyonce-knowles']\n",
    "df_songs_political = df_songs[df_songs['artist'].isin(political_artists)]\n",
    "df_songs_political.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_songs_political=df_songs_political.dropna(subset=['lyrics'])\n",
    "df_songs_political['lyrics'] = df_songs_political['lyrics'].apply(lambda x: x.replace('\\n',' '))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_songs_politcal_lyrics= list(df_songs_political.iloc[:,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we begin to implement some of the NLP\n",
    "\n",
    "Implement stemming after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemmer = EnglishStemmer()\n",
    "#analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def stemmed_words(document):\n",
    "    stemmer = EnglishStemmer()\n",
    "    analyzer = CountVectorizer().build_analyzer()\n",
    "    return (stemmer.stem(x) for x in analyzer(document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_songs_political['lyrics'] = df_songs_political['lyrics'].apply(lambda x: stemmed_words(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_songs_political['lyrics']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_stemmed=CountVectorizer(stop_words = 'english', analyzer=stemmed_words,min_df = 5, max_df=0.9)\n",
    "# cv_stemmed_lyrics=cv_stemmed.fit(df_song_lyrics)\n",
    "# cv_stemmed_lyrics=cv_stemmed.transform(df_song_lyrics)\n",
    "# cv_stemmed_lyrics.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note below we have the version where we are taking TFIDF Weights. In reality, this would be harder to implement. In practice, we will use a pretrained model that will be able to return a vector to compare similarities. Also, we will want to restrict the size of our data in order to make comparisons feasible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement embedding below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0820 22:17:55.914290 4677940672 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings...\n"
     ]
    }
   ],
   "source": [
    "df_songs_beyonce_lyrics_embed = embed(df_songs_beyonce_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_songs_beyonce_lyrics_embed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we start to get the comparison to the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forthehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_stemmed_article = cv_stemmed.transform(list(article_text))\n",
    "# tf_idf_article_vector = vectorizer.transform(cv_stemmed_article)\n",
    "# print(tf_idf_article_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tf_idf_article_vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
